inputs = [1, 2, 3, 2.5]

weights = [[0.2, 0.8, -0.5, 1.0],
           [0.5, -0.91, 0.26, -0.5],
           [-0.26, -0.27, 0.17, 0.87]]

biases = [2, 3, 0.5] #offsets the value after the weight has been mmultiplied

#zip: combines 2 lists into a list of lists

layer_outputs = [] #outpus of current layer
for neuron_weights, neuron_bias in zip(weights, biases):
    neuron_output = 0 #output of given neuron 

    for n_input, weight in zip(inputs, neuron_weights):
        neuron_output += n_input*weight

    neuron_output += neuron_bias # more dynamic way of doing inputs*weights + bias
    layer_outputs.append(neuron_output)

#weights and bias are what is tuned to minipulate data changes to the output fromm the input

print(layer_outputs)

#shape, describes an array (or vector in math)

#1d array = [1,3,5,9]
    # shape is (4) because it has 4 values

#2d array = [[1,2,3,4],
#            [9,3,4,5]]
    # shape is (2, 4) because array has 2 items, each item-array has 4 vals
    # This is a mathematical matrix

# A shap can only describe a homologous array, an array with the same number of elements in the context of other items in the parent array

# -----------------------

# Dot product

# a = [1,2,3]
# b = [4,5,6]

# dot_prod = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]